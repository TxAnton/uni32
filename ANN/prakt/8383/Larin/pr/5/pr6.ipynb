{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pr6.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7GySZ0JopIu"
      },
      "source": [
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Convolution2D, MaxPooling2D, Dense, Dropout, Flatten\n",
        "from tensorflow.keras import utils\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import var5\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5pmjhu_pves"
      },
      "source": [
        "\n",
        "batch_size = 32\n",
        "num_epochs = 200\n",
        "kernel_size = 4\n",
        "pool_size = 2\n",
        "conv_depth_1 = 32\n",
        "conv_depth_2 = 64\n",
        "drop_prob_1 = 0.25\n",
        "drop_prob_2 = 0.5\n",
        "hidden_size = 512\n",
        "\n",
        "size = 400\n",
        "img_size = 50\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozb3IOfNpzG5",
        "outputId": "d6fa8c22-115e-416a-b722-4180f03651f2"
      },
      "source": [
        "data, labels = var5.gen_data(size,img_size)\n",
        "# labels.reshape(labels.size)\n",
        "data, labels = shuffle(data,labels)\n",
        "num_classes = np.unique(labels).shape[0]\n",
        "le.fit(labels)\n",
        "labels = le.transform(labels)\n",
        "labels = utils.to_categorical(labels, num_classes) # One-hot encode the labels\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYD7bYyRp6EO",
        "outputId": "919d88aa-b834-43aa-a62c-66d3cdf93754"
      },
      "source": [
        "inp = Input(shape=(img_size, img_size,1))\n",
        "\n",
        "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
        "layer = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(inp)\n",
        "layer = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(layer)\n",
        "layer = MaxPooling2D(pool_size=(pool_size, pool_size))(layer)\n",
        "layer = Dropout(drop_prob_1)(layer)\n",
        "\n",
        "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
        "layer = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(inp)\n",
        "layer = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(layer)\n",
        "layer = MaxPooling2D(pool_size=(pool_size, pool_size))(layer)\n",
        "layer = Dropout(drop_prob_1)(layer)\n",
        "\n",
        "\n",
        "flat = Flatten()(layer)\n",
        "\n",
        "layer = Dense(hidden_size, activation='relu')(flat)\n",
        "layer = Dropout(drop_prob_2)(layer)\n",
        "out = Dense(num_classes, activation='softmax')(layer)\n",
        "\n",
        "\n",
        "model = Model(inputs=inp, outputs=out)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "H = model.fit(data,labels,\n",
        "              batch_size=batch_size,\n",
        "              epochs=num_epochs,\n",
        "              verbose=1,\n",
        "              validation_split=.1)\n",
        "\n",
        "model.evaluate(data, labels, verbose=1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "12/12 [==============================] - 1s 26ms/step - loss: 0.7088 - accuracy: 0.5946 - val_loss: 0.8548 - val_accuracy: 0.4750\n",
            "Epoch 2/200\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.4447 - accuracy: 0.7931 - val_loss: 0.1722 - val_accuracy: 0.9750\n",
            "Epoch 3/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1244 - accuracy: 0.9598 - val_loss: 0.0431 - val_accuracy: 1.0000\n",
            "Epoch 4/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0263 - accuracy: 0.9959 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
            "Epoch 5/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
            "Epoch 6/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 7/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 4.2095e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 8/200\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 4.9594e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 9/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.4432e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 10/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.0294e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 11/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.4889e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 12/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.4086e-04 - accuracy: 1.0000 - val_loss: 9.5724e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.3300e-04 - accuracy: 1.0000 - val_loss: 8.5099e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.0182e-04 - accuracy: 1.0000 - val_loss: 7.6048e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.3548e-04 - accuracy: 1.0000 - val_loss: 7.0162e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.5053e-05 - accuracy: 1.0000 - val_loss: 6.4608e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4737e-05 - accuracy: 1.0000 - val_loss: 6.1623e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 7.6524e-05 - accuracy: 1.0000 - val_loss: 6.2645e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7485e-05 - accuracy: 1.0000 - val_loss: 5.1121e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.6908e-05 - accuracy: 1.0000 - val_loss: 4.7519e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7655e-05 - accuracy: 1.0000 - val_loss: 4.6444e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 5.0967e-05 - accuracy: 1.0000 - val_loss: 4.4129e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/200\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 6.7392e-05 - accuracy: 1.0000 - val_loss: 4.1983e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.3910e-05 - accuracy: 1.0000 - val_loss: 4.4118e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.8232e-05 - accuracy: 1.0000 - val_loss: 3.6112e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.8402e-05 - accuracy: 1.0000 - val_loss: 3.5792e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 5.6763e-05 - accuracy: 1.0000 - val_loss: 3.2527e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.6730e-05 - accuracy: 1.0000 - val_loss: 3.1132e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8254e-05 - accuracy: 1.0000 - val_loss: 3.4889e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 4.0178e-05 - accuracy: 1.0000 - val_loss: 3.8472e-04 - val_accuracy: 1.0000\n",
            "Epoch 31/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.6373e-05 - accuracy: 1.0000 - val_loss: 3.3764e-04 - val_accuracy: 1.0000\n",
            "Epoch 32/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.6137e-05 - accuracy: 1.0000 - val_loss: 2.5535e-04 - val_accuracy: 1.0000\n",
            "Epoch 33/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.1770e-05 - accuracy: 1.0000 - val_loss: 2.3863e-04 - val_accuracy: 1.0000\n",
            "Epoch 34/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.6150e-05 - accuracy: 1.0000 - val_loss: 2.7478e-04 - val_accuracy: 1.0000\n",
            "Epoch 35/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.8678e-05 - accuracy: 1.0000 - val_loss: 2.3061e-04 - val_accuracy: 1.0000\n",
            "Epoch 36/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.2583e-05 - accuracy: 1.0000 - val_loss: 2.3964e-04 - val_accuracy: 1.0000\n",
            "Epoch 37/200\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 2.3221e-05 - accuracy: 1.0000 - val_loss: 2.1795e-04 - val_accuracy: 1.0000\n",
            "Epoch 38/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.7112e-05 - accuracy: 1.0000 - val_loss: 2.2147e-04 - val_accuracy: 1.0000\n",
            "Epoch 39/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.3784e-05 - accuracy: 1.0000 - val_loss: 2.5146e-04 - val_accuracy: 1.0000\n",
            "Epoch 40/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.7254e-05 - accuracy: 1.0000 - val_loss: 2.0655e-04 - val_accuracy: 1.0000\n",
            "Epoch 41/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.4389e-05 - accuracy: 1.0000 - val_loss: 1.9764e-04 - val_accuracy: 1.0000\n",
            "Epoch 42/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.1238e-05 - accuracy: 1.0000 - val_loss: 2.2366e-04 - val_accuracy: 1.0000\n",
            "Epoch 43/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.6493e-05 - accuracy: 1.0000 - val_loss: 1.7276e-04 - val_accuracy: 1.0000\n",
            "Epoch 44/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.5371e-05 - accuracy: 1.0000 - val_loss: 1.7723e-04 - val_accuracy: 1.0000\n",
            "Epoch 45/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.6856e-05 - accuracy: 1.0000 - val_loss: 1.8001e-04 - val_accuracy: 1.0000\n",
            "Epoch 46/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.1432e-05 - accuracy: 1.0000 - val_loss: 1.7559e-04 - val_accuracy: 1.0000\n",
            "Epoch 47/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.2537e-05 - accuracy: 1.0000 - val_loss: 1.4563e-04 - val_accuracy: 1.0000\n",
            "Epoch 48/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.4366e-05 - accuracy: 1.0000 - val_loss: 1.5788e-04 - val_accuracy: 1.0000\n",
            "Epoch 49/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.1352e-05 - accuracy: 1.0000 - val_loss: 1.7749e-04 - val_accuracy: 1.0000\n",
            "Epoch 50/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.2362e-05 - accuracy: 1.0000 - val_loss: 1.4840e-04 - val_accuracy: 1.0000\n",
            "Epoch 51/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.2771e-05 - accuracy: 1.0000 - val_loss: 1.3193e-04 - val_accuracy: 1.0000\n",
            "Epoch 52/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.6488e-05 - accuracy: 1.0000 - val_loss: 1.4346e-04 - val_accuracy: 1.0000\n",
            "Epoch 53/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.1657e-05 - accuracy: 1.0000 - val_loss: 1.1804e-04 - val_accuracy: 1.0000\n",
            "Epoch 54/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.1420e-05 - accuracy: 1.0000 - val_loss: 1.2277e-04 - val_accuracy: 1.0000\n",
            "Epoch 55/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.1960e-05 - accuracy: 1.0000 - val_loss: 1.2842e-04 - val_accuracy: 1.0000\n",
            "Epoch 56/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.0150e-05 - accuracy: 1.0000 - val_loss: 1.5355e-04 - val_accuracy: 1.0000\n",
            "Epoch 57/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 9.4436e-06 - accuracy: 1.0000 - val_loss: 1.6107e-04 - val_accuracy: 1.0000\n",
            "Epoch 58/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 7.2062e-06 - accuracy: 1.0000 - val_loss: 1.4913e-04 - val_accuracy: 1.0000\n",
            "Epoch 59/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.2297e-05 - accuracy: 1.0000 - val_loss: 1.2378e-04 - val_accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 7.6417e-06 - accuracy: 1.0000 - val_loss: 1.1883e-04 - val_accuracy: 1.0000\n",
            "Epoch 61/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.0120e-05 - accuracy: 1.0000 - val_loss: 1.0103e-04 - val_accuracy: 1.0000\n",
            "Epoch 62/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 7.5320e-06 - accuracy: 1.0000 - val_loss: 1.1119e-04 - val_accuracy: 1.0000\n",
            "Epoch 63/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 7.6288e-06 - accuracy: 1.0000 - val_loss: 1.2115e-04 - val_accuracy: 1.0000\n",
            "Epoch 64/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8058e-06 - accuracy: 1.0000 - val_loss: 1.1626e-04 - val_accuracy: 1.0000\n",
            "Epoch 65/200\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.5467e-06 - accuracy: 1.0000 - val_loss: 1.0636e-04 - val_accuracy: 1.0000\n",
            "Epoch 66/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 5.9470e-06 - accuracy: 1.0000 - val_loss: 1.1035e-04 - val_accuracy: 1.0000\n",
            "Epoch 67/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 7.5822e-06 - accuracy: 1.0000 - val_loss: 1.1708e-04 - val_accuracy: 1.0000\n",
            "Epoch 68/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 7.7562e-06 - accuracy: 1.0000 - val_loss: 1.1631e-04 - val_accuracy: 1.0000\n",
            "Epoch 69/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6579e-06 - accuracy: 1.0000 - val_loss: 1.0958e-04 - val_accuracy: 1.0000\n",
            "Epoch 70/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.8849e-06 - accuracy: 1.0000 - val_loss: 1.1380e-04 - val_accuracy: 1.0000\n",
            "Epoch 71/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 4.9546e-06 - accuracy: 1.0000 - val_loss: 8.6983e-05 - val_accuracy: 1.0000\n",
            "Epoch 72/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 7.1563e-06 - accuracy: 1.0000 - val_loss: 8.5780e-05 - val_accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 7.3583e-06 - accuracy: 1.0000 - val_loss: 9.6005e-05 - val_accuracy: 1.0000\n",
            "Epoch 74/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.2845e-06 - accuracy: 1.0000 - val_loss: 8.8339e-05 - val_accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 4.9092e-06 - accuracy: 1.0000 - val_loss: 7.7826e-05 - val_accuracy: 1.0000\n",
            "Epoch 76/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 5.1995e-06 - accuracy: 1.0000 - val_loss: 7.4138e-05 - val_accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 5.4079e-06 - accuracy: 1.0000 - val_loss: 7.9265e-05 - val_accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 4.9462e-06 - accuracy: 1.0000 - val_loss: 8.9678e-05 - val_accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 5.8616e-06 - accuracy: 1.0000 - val_loss: 8.6724e-05 - val_accuracy: 1.0000\n",
            "Epoch 80/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 4.2254e-06 - accuracy: 1.0000 - val_loss: 7.1893e-05 - val_accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 5.4729e-06 - accuracy: 1.0000 - val_loss: 6.5508e-05 - val_accuracy: 1.0000\n",
            "Epoch 82/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.1753e-06 - accuracy: 1.0000 - val_loss: 7.8790e-05 - val_accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 5.3425e-06 - accuracy: 1.0000 - val_loss: 7.6421e-05 - val_accuracy: 1.0000\n",
            "Epoch 84/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 4.3569e-06 - accuracy: 1.0000 - val_loss: 7.1477e-05 - val_accuracy: 1.0000\n",
            "Epoch 85/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 4.9258e-06 - accuracy: 1.0000 - val_loss: 7.0785e-05 - val_accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 4.1662e-06 - accuracy: 1.0000 - val_loss: 6.9939e-05 - val_accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.8184e-06 - accuracy: 1.0000 - val_loss: 7.2924e-05 - val_accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.6954e-06 - accuracy: 1.0000 - val_loss: 7.3729e-05 - val_accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 3.9641e-06 - accuracy: 1.0000 - val_loss: 7.0069e-05 - val_accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 4.9052e-06 - accuracy: 1.0000 - val_loss: 6.7198e-05 - val_accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.4791e-06 - accuracy: 1.0000 - val_loss: 8.0902e-05 - val_accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 4.5588e-06 - accuracy: 1.0000 - val_loss: 7.1881e-05 - val_accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9754e-06 - accuracy: 1.0000 - val_loss: 6.1945e-05 - val_accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 3.1065e-06 - accuracy: 1.0000 - val_loss: 6.4107e-05 - val_accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 4.2508e-06 - accuracy: 1.0000 - val_loss: 5.7617e-05 - val_accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 3.8136e-06 - accuracy: 1.0000 - val_loss: 6.1576e-05 - val_accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.0010e-06 - accuracy: 1.0000 - val_loss: 5.6732e-05 - val_accuracy: 1.0000\n",
            "Epoch 98/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8552e-06 - accuracy: 1.0000 - val_loss: 4.7737e-05 - val_accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 3.3933e-06 - accuracy: 1.0000 - val_loss: 5.6615e-05 - val_accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.3843e-06 - accuracy: 1.0000 - val_loss: 6.0021e-05 - val_accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.7120e-06 - accuracy: 1.0000 - val_loss: 5.7081e-05 - val_accuracy: 1.0000\n",
            "Epoch 102/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 3.8611e-06 - accuracy: 1.0000 - val_loss: 5.5205e-05 - val_accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 3.4546e-06 - accuracy: 1.0000 - val_loss: 5.3255e-05 - val_accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 6.6980e-06 - accuracy: 1.0000 - val_loss: 4.4265e-05 - val_accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.7524e-06 - accuracy: 1.0000 - val_loss: 4.8606e-05 - val_accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.6265e-06 - accuracy: 1.0000 - val_loss: 4.9356e-05 - val_accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.7000e-06 - accuracy: 1.0000 - val_loss: 5.1191e-05 - val_accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.1673e-06 - accuracy: 1.0000 - val_loss: 5.0667e-05 - val_accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 3.9196e-06 - accuracy: 1.0000 - val_loss: 4.9160e-05 - val_accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.3245e-06 - accuracy: 1.0000 - val_loss: 4.9294e-05 - val_accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.7607e-06 - accuracy: 1.0000 - val_loss: 4.9737e-05 - val_accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 7.2652e-06 - accuracy: 1.0000 - val_loss: 4.1718e-05 - val_accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.4471e-06 - accuracy: 1.0000 - val_loss: 4.8355e-05 - val_accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.3699e-06 - accuracy: 1.0000 - val_loss: 4.7619e-05 - val_accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 4.5171e-06 - accuracy: 1.0000 - val_loss: 3.8436e-05 - val_accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.1555e-06 - accuracy: 1.0000 - val_loss: 4.4863e-05 - val_accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.1062e-06 - accuracy: 1.0000 - val_loss: 5.0622e-05 - val_accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.6297e-06 - accuracy: 1.0000 - val_loss: 5.5722e-05 - val_accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9730e-06 - accuracy: 1.0000 - val_loss: 5.0427e-05 - val_accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 3.0450e-06 - accuracy: 1.0000 - val_loss: 3.8163e-05 - val_accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.4294e-06 - accuracy: 1.0000 - val_loss: 3.6195e-05 - val_accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 3.0865e-06 - accuracy: 1.0000 - val_loss: 3.5043e-05 - val_accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.8934e-06 - accuracy: 1.0000 - val_loss: 3.8344e-05 - val_accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.7756e-06 - accuracy: 1.0000 - val_loss: 4.2044e-05 - val_accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.6607e-06 - accuracy: 1.0000 - val_loss: 3.8820e-05 - val_accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.6814e-06 - accuracy: 1.0000 - val_loss: 3.3949e-05 - val_accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1.7523e-06 - accuracy: 1.0000 - val_loss: 3.3675e-05 - val_accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.6554e-06 - accuracy: 1.0000 - val_loss: 3.7102e-05 - val_accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.3253e-06 - accuracy: 1.0000 - val_loss: 3.6786e-05 - val_accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.2872e-06 - accuracy: 1.0000 - val_loss: 3.7089e-05 - val_accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.6117e-06 - accuracy: 1.0000 - val_loss: 3.6410e-05 - val_accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.5291e-06 - accuracy: 1.0000 - val_loss: 3.3853e-05 - val_accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.9881e-06 - accuracy: 1.0000 - val_loss: 3.1381e-05 - val_accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.7749e-06 - accuracy: 1.0000 - val_loss: 3.5651e-05 - val_accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.5220e-06 - accuracy: 1.0000 - val_loss: 3.6365e-05 - val_accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.4184e-06 - accuracy: 1.0000 - val_loss: 3.5329e-05 - val_accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.3416e-06 - accuracy: 1.0000 - val_loss: 3.1319e-05 - val_accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.0622e-06 - accuracy: 1.0000 - val_loss: 2.7289e-05 - val_accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.1385e-06 - accuracy: 1.0000 - val_loss: 3.5921e-05 - val_accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.4908e-06 - accuracy: 1.0000 - val_loss: 3.7865e-05 - val_accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.1494e-06 - accuracy: 1.0000 - val_loss: 3.6469e-05 - val_accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.3778e-06 - accuracy: 1.0000 - val_loss: 3.4935e-05 - val_accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.3302e-06 - accuracy: 1.0000 - val_loss: 3.4143e-05 - val_accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.4626e-06 - accuracy: 1.0000 - val_loss: 3.2707e-05 - val_accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.5444e-06 - accuracy: 1.0000 - val_loss: 2.5921e-05 - val_accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.5886e-06 - accuracy: 1.0000 - val_loss: 3.2091e-05 - val_accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.2825e-06 - accuracy: 1.0000 - val_loss: 3.2421e-05 - val_accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.7638e-06 - accuracy: 1.0000 - val_loss: 3.3038e-05 - val_accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.5300e-06 - accuracy: 1.0000 - val_loss: 3.0515e-05 - val_accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1.5787e-06 - accuracy: 1.0000 - val_loss: 2.5387e-05 - val_accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.0136e-06 - accuracy: 1.0000 - val_loss: 2.8398e-05 - val_accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.6726e-06 - accuracy: 1.0000 - val_loss: 3.2156e-05 - val_accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.0620e-06 - accuracy: 1.0000 - val_loss: 3.1718e-05 - val_accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 7.6688e-07 - accuracy: 1.0000 - val_loss: 2.8645e-05 - val_accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.4025e-06 - accuracy: 1.0000 - val_loss: 2.9532e-05 - val_accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.8265e-07 - accuracy: 1.0000 - val_loss: 2.8844e-05 - val_accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1.2844e-06 - accuracy: 1.0000 - val_loss: 2.9231e-05 - val_accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1.6016e-06 - accuracy: 1.0000 - val_loss: 2.1893e-05 - val_accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1.1028e-06 - accuracy: 1.0000 - val_loss: 2.3400e-05 - val_accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.4299e-06 - accuracy: 1.0000 - val_loss: 2.6026e-05 - val_accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.4763e-06 - accuracy: 1.0000 - val_loss: 2.4832e-05 - val_accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.3950e-06 - accuracy: 1.0000 - val_loss: 2.4180e-05 - val_accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1.2719e-06 - accuracy: 1.0000 - val_loss: 2.4439e-05 - val_accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.5055e-06 - accuracy: 1.0000 - val_loss: 2.6133e-05 - val_accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.1408e-06 - accuracy: 1.0000 - val_loss: 2.6592e-05 - val_accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.1607e-06 - accuracy: 1.0000 - val_loss: 2.1725e-05 - val_accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.0928e-06 - accuracy: 1.0000 - val_loss: 2.1374e-05 - val_accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.0950e-06 - accuracy: 1.0000 - val_loss: 2.5406e-05 - val_accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.5625e-06 - accuracy: 1.0000 - val_loss: 2.3238e-05 - val_accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.1319e-06 - accuracy: 1.0000 - val_loss: 2.3116e-05 - val_accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.0821e-06 - accuracy: 1.0000 - val_loss: 2.5606e-05 - val_accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.1693e-07 - accuracy: 1.0000 - val_loss: 2.6440e-05 - val_accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8425e-07 - accuracy: 1.0000 - val_loss: 2.6359e-05 - val_accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.0791e-06 - accuracy: 1.0000 - val_loss: 1.9068e-05 - val_accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.5721e-07 - accuracy: 1.0000 - val_loss: 2.2624e-05 - val_accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 9.2825e-07 - accuracy: 1.0000 - val_loss: 2.2434e-05 - val_accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.0500e-06 - accuracy: 1.0000 - val_loss: 1.8815e-05 - val_accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8864e-07 - accuracy: 1.0000 - val_loss: 1.9300e-05 - val_accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.1459e-06 - accuracy: 1.0000 - val_loss: 1.9217e-05 - val_accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.2534e-06 - accuracy: 1.0000 - val_loss: 2.0009e-05 - val_accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 7.9360e-07 - accuracy: 1.0000 - val_loss: 2.0899e-05 - val_accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.0426e-06 - accuracy: 1.0000 - val_loss: 1.7831e-05 - val_accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7411e-07 - accuracy: 1.0000 - val_loss: 1.7298e-05 - val_accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.1708e-06 - accuracy: 1.0000 - val_loss: 1.9759e-05 - val_accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.5833e-07 - accuracy: 1.0000 - val_loss: 1.8796e-05 - val_accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1.1039e-06 - accuracy: 1.0000 - val_loss: 2.0187e-05 - val_accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 9.7603e-07 - accuracy: 1.0000 - val_loss: 2.2773e-05 - val_accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1.1679e-06 - accuracy: 1.0000 - val_loss: 1.9729e-05 - val_accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.2047e-07 - accuracy: 1.0000 - val_loss: 1.5427e-05 - val_accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.1725e-06 - accuracy: 1.0000 - val_loss: 1.7235e-05 - val_accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 7.5875e-07 - accuracy: 1.0000 - val_loss: 2.0137e-05 - val_accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.2307e-07 - accuracy: 1.0000 - val_loss: 2.0699e-05 - val_accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4744e-07 - accuracy: 1.0000 - val_loss: 1.8876e-05 - val_accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.0018e-06 - accuracy: 1.0000 - val_loss: 1.4197e-05 - val_accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.3372e-06 - accuracy: 1.0000 - val_loss: 1.3818e-05 - val_accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 9.6445e-07 - accuracy: 1.0000 - val_loss: 1.7185e-05 - val_accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 7.2779e-07 - accuracy: 1.0000 - val_loss: 1.6321e-05 - val_accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.3420e-06 - accuracy: 1.0000 - val_loss: 1.6121e-05 - val_accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3717e-07 - accuracy: 1.0000 - val_loss: 1.6085e-05 - val_accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.2128e-07 - accuracy: 1.0000 - val_loss: 1.7026e-05 - val_accuracy: 1.0000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 1.9306e-06 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.9306305603095097e-06, 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}