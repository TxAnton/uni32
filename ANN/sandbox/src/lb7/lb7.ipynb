{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N3iHri-ydV3T"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Lambda\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eEI2owBidaUL",
    "outputId": "a636fc77-be1d-4b10-aba8-f43dcd23c607"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "top_words = 10000\n",
    "(X_train, Y_train), (X_test, Y_test) = imdb.load_data(num_words=top_words)\n",
    "data = np.concatenate((X_train, X_test), axis=0)\n",
    "targets = np.concatenate((Y_train, Y_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7wSao6Sqdcl1"
   },
   "outputs": [],
   "source": [
    "max_review_length = 500\n",
    "data = sequence.pad_sequences(data, maxlen=max_review_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CdnsYBG-df_h"
   },
   "outputs": [],
   "source": [
    "embedding_vector_length = 32\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4M6vmz7rxoOC"
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Embedding(top_words, embedding_vector_length, input_length=max_review_length))\n",
    "# model.add(LSTM(100))\n",
    "# model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vo4BnnsW1xfT"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EbwtVnwB1Riq",
    "outputId": "f7d4f964-c4eb-4f9f-b73c-a767bf19cc98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "625/625 [==============================] - 16s 24ms/step - loss: 0.5126 - accuracy: 0.7167 - val_loss: 0.2639 - val_accuracy: 0.8964\n",
      "Epoch 2/3\n",
      "625/625 [==============================] - 14s 23ms/step - loss: 0.2114 - accuracy: 0.9187 - val_loss: 0.2684 - val_accuracy: 0.8890\n",
      "Epoch 3/3\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.1609 - accuracy: 0.9436 - val_loss: 0.2631 - val_accuracy: 0.8943\n",
      "Epoch 1/3\n",
      "625/625 [==============================] - 16s 24ms/step - loss: 0.5325 - accuracy: 0.6856 - val_loss: 0.2717 - val_accuracy: 0.8919\n",
      "Epoch 2/3\n",
      "625/625 [==============================] - 14s 23ms/step - loss: 0.2144 - accuracy: 0.9196 - val_loss: 0.2645 - val_accuracy: 0.8924\n",
      "Epoch 3/3\n",
      "625/625 [==============================] - 14s 23ms/step - loss: 0.1751 - accuracy: 0.9372 - val_loss: 0.2823 - val_accuracy: 0.8923\n",
      "Epoch 1/3\n",
      "625/625 [==============================] - 16s 24ms/step - loss: 0.5426 - accuracy: 0.6764 - val_loss: 0.2573 - val_accuracy: 0.8975\n",
      "Epoch 2/3\n",
      "625/625 [==============================] - 15s 23ms/step - loss: 0.2278 - accuracy: 0.9134 - val_loss: 0.2604 - val_accuracy: 0.8996\n",
      "Epoch 3/3\n",
      "625/625 [==============================] - 14s 23ms/step - loss: 0.1662 - accuracy: 0.9399 - val_loss: 0.2631 - val_accuracy: 0.8981\n",
      "Epoch 1/3\n",
      "625/625 [==============================] - 16s 24ms/step - loss: 0.5013 - accuracy: 0.7178 - val_loss: 0.2770 - val_accuracy: 0.8859\n",
      "Epoch 2/3\n",
      "625/625 [==============================] - 14s 23ms/step - loss: 0.2153 - accuracy: 0.9193 - val_loss: 0.2649 - val_accuracy: 0.8961\n",
      "Epoch 3/3\n",
      "625/625 [==============================] - 14s 23ms/step - loss: 0.1614 - accuracy: 0.9422 - val_loss: 0.2660 - val_accuracy: 0.8943\n",
      "Epoch 1/3\n",
      "625/625 [==============================] - 16s 24ms/step - loss: 0.5223 - accuracy: 0.7073 - val_loss: 0.2788 - val_accuracy: 0.8891\n",
      "Epoch 2/3\n",
      "625/625 [==============================] - 14s 23ms/step - loss: 0.2234 - accuracy: 0.9159 - val_loss: 0.2769 - val_accuracy: 0.8858\n",
      "Epoch 3/3\n",
      "625/625 [==============================] - 14s 23ms/step - loss: 0.1792 - accuracy: 0.9333 - val_loss: 0.2452 - val_accuracy: 0.8989\n"
     ]
    }
   ],
   "source": [
    "# Fit ansamble\n",
    "models = []\n",
    "n_models = 5\n",
    "n_samples = int(len(data) / n_models)\n",
    "\n",
    "for i in range(0, n_models):\n",
    "    test_x = data[i * n_samples:(i + 1) * n_samples]\n",
    "    test_y = targets[i * n_samples:(i + 1) * n_samples]\n",
    "    train_x = np.concatenate([data[:i * n_samples], data[(i + 1) * n_samples:]], axis=0)\n",
    "    train_y = np.concatenate([targets[:i * n_samples], targets[(i + 1) * n_samples:]], axis=0)\n",
    "\n",
    "    train_x = sequence.pad_sequences(train_x, maxlen=max_review_length)\n",
    "    test_x = sequence.pad_sequences(test_x, maxlen=max_review_length)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "    model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(train_x, train_y, validation_data=(test_x, test_y), epochs=3, batch_size=64)\n",
    "    model.save('model' + str(i) + '.h5')\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aaMdYR3W3hRw"
   },
   "outputs": [],
   "source": [
    "# evaluate ansample\n",
    "\n",
    "\n",
    "def ans(_inp):\n",
    "  res=[]\n",
    "  for i in range(len(models)):\n",
    "    outp = models[i].predict(_inp)\n",
    "    res.append(outp)\n",
    "\n",
    "  return sum(res)/len(res)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DUkwuaEBdis9",
    "outputId": "d321ccff-702b-4023-819f-1877a82cc644"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 500, 32)           320000    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 500, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 250, 128)          82432     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 455,009\n",
      "Trainable params: 455,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "625/625 [==============================] - 27s 35ms/step - loss: 0.5188 - accuracy: 0.7141 - val_loss: 0.3572 - val_accuracy: 0.8542\n",
      "Epoch 2/3\n",
      "625/625 [==============================] - 21s 33ms/step - loss: 0.2562 - accuracy: 0.9003 - val_loss: 0.2476 - val_accuracy: 0.8981\n",
      "Epoch 3/3\n",
      "625/625 [==============================] - 21s 33ms/step - loss: 0.1786 - accuracy: 0.9355 - val_loss: 0.2468 - val_accuracy: 0.8980\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# print(model.summary())\n",
    "# H = model.fit(data, targets, validation_split=.2, epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u41xWcQpiqpB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
