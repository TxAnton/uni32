{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2uJ1Q16fJuG"
      },
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wADhEts2kMHh"
      },
      "source": [
        "import os"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DV0bs8JkMJZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1c3ccb2-cbec-4b0e-87d3-0df556d4e9e3"
      },
      "source": [
        "os.path.exists(\"wonderland.txt\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlreOyVCfP7W"
      },
      "source": [
        "filename = \"wonderland.txt\"\n",
        "raw_text = open(filename).read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpQ6-2-ifQBO"
      },
      "source": [
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfBu6hCXfQIq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2310fa42-d351-40c7-b1f9-1a1fe2544d3d"
      },
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  144430\n",
            "Total Vocab:  45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR-liTDsh42S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12c85bcf-8220-4715-8bcd-f85bead3e1ed"
      },
      "source": [
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "        seq_in = raw_text[i:i + seq_length]\n",
        "        seq_out = raw_text[i + seq_length]\n",
        "        dataX.append([char_to_int[char] for char in seq_in])\n",
        "        dataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  144330\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5sd3Wh-h44R"
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oltV9qsh452"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86KKJfI8ixHL"
      },
      "source": [
        "# define the checkpoint\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d02XTxu_ixJc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78f0f908-0384-4cdd-800f-0cc987548819"
      },
      "source": [
        "H = model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1128/1128 [==============================] - 48s 14ms/step - loss: 3.0502\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.96460, saving model to weights-improvement-01-2.9646.hdf5\n",
            "Epoch 2/20\n",
            "1128/1128 [==============================] - 16s 14ms/step - loss: 2.7908\n",
            "\n",
            "Epoch 00002: loss improved from 2.96460 to 2.76241, saving model to weights-improvement-02-2.7624.hdf5\n",
            "Epoch 3/20\n",
            "1128/1128 [==============================] - 16s 14ms/step - loss: 2.6813\n",
            "\n",
            "Epoch 00003: loss improved from 2.76241 to 2.65770, saving model to weights-improvement-03-2.6577.hdf5\n",
            "Epoch 4/20\n",
            "1128/1128 [==============================] - 16s 14ms/step - loss: 2.6015\n",
            "\n",
            "Epoch 00004: loss improved from 2.65770 to 2.58180, saving model to weights-improvement-04-2.5818.hdf5\n",
            "Epoch 5/20\n",
            "1128/1128 [==============================] - 17s 15ms/step - loss: 2.5318\n",
            "\n",
            "Epoch 00005: loss improved from 2.58180 to 2.51955, saving model to weights-improvement-05-2.5196.hdf5\n",
            "Epoch 6/20\n",
            "1128/1128 [==============================] - 17s 15ms/step - loss: 2.4713\n",
            "\n",
            "Epoch 00006: loss improved from 2.51955 to 2.46607, saving model to weights-improvement-06-2.4661.hdf5\n",
            "Epoch 7/20\n",
            "1128/1128 [==============================] - 16s 15ms/step - loss: 2.4223\n",
            "\n",
            "Epoch 00007: loss improved from 2.46607 to 2.41450, saving model to weights-improvement-07-2.4145.hdf5\n",
            "Epoch 8/20\n",
            "1128/1128 [==============================] - 16s 14ms/step - loss: 2.3672\n",
            "\n",
            "Epoch 00008: loss improved from 2.41450 to 2.36600, saving model to weights-improvement-08-2.3660.hdf5\n",
            "Epoch 9/20\n",
            "1128/1128 [==============================] - 16s 14ms/step - loss: 2.3143\n",
            "\n",
            "Epoch 00009: loss improved from 2.36600 to 2.32122, saving model to weights-improvement-09-2.3212.hdf5\n",
            "Epoch 10/20\n",
            "1128/1128 [==============================] - 16s 14ms/step - loss: 2.2761\n",
            "\n",
            "Epoch 00010: loss improved from 2.32122 to 2.27673, saving model to weights-improvement-10-2.2767.hdf5\n",
            "Epoch 11/20\n",
            "1128/1128 [==============================] - 16s 14ms/step - loss: 2.2317\n",
            "\n",
            "Epoch 00011: loss improved from 2.27673 to 2.23629, saving model to weights-improvement-11-2.2363.hdf5\n",
            "Epoch 12/20\n",
            "1128/1128 [==============================] - 16s 14ms/step - loss: 2.1908\n",
            "\n",
            "Epoch 00012: loss improved from 2.23629 to 2.19626, saving model to weights-improvement-12-2.1963.hdf5\n",
            "Epoch 13/20\n",
            "1128/1128 [==============================] - 16s 15ms/step - loss: 2.1552\n",
            "\n",
            "Epoch 00013: loss improved from 2.19626 to 2.15985, saving model to weights-improvement-13-2.1599.hdf5\n",
            "Epoch 14/20\n",
            "1128/1128 [==============================] - 16s 14ms/step - loss: 2.1143\n",
            "\n",
            "Epoch 00014: loss improved from 2.15985 to 2.12373, saving model to weights-improvement-14-2.1237.hdf5\n",
            "Epoch 15/20\n",
            "1128/1128 [==============================] - 16s 14ms/step - loss: 2.0856\n",
            "\n",
            "Epoch 00015: loss improved from 2.12373 to 2.08934, saving model to weights-improvement-15-2.0893.hdf5\n",
            "Epoch 16/20\n",
            "1128/1128 [==============================] - 16s 14ms/step - loss: 2.0520\n",
            "\n",
            "Epoch 00016: loss improved from 2.08934 to 2.05748, saving model to weights-improvement-16-2.0575.hdf5\n",
            "Epoch 17/20\n",
            "1128/1128 [==============================] - 16s 14ms/step - loss: 2.0186\n",
            "\n",
            "Epoch 00017: loss improved from 2.05748 to 2.02903, saving model to weights-improvement-17-2.0290.hdf5\n",
            "Epoch 18/20\n",
            "1128/1128 [==============================] - 16s 14ms/step - loss: 1.9870\n",
            "\n",
            "Epoch 00018: loss improved from 2.02903 to 1.99739, saving model to weights-improvement-18-1.9974.hdf5\n",
            "Epoch 19/20\n",
            "1128/1128 [==============================] - 16s 14ms/step - loss: 1.9571\n",
            "\n",
            "Epoch 00019: loss improved from 1.99739 to 1.96934, saving model to weights-improvement-19-1.9693.hdf5\n",
            "Epoch 20/20\n",
            "1128/1128 [==============================] - 16s 14ms/step - loss: 1.9367\n",
            "\n",
            "Epoch 00020: loss improved from 1.96934 to 1.94404, saving model to weights-improvement-20-1.9440.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAMoXLnTjDW7"
      },
      "source": [
        ""
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Llq0F_kVjDYs"
      },
      "source": [
        "# load the network weights\n",
        "# filename = \"weights-improvement-20-1.9440.hdf5\"\n",
        "filename = \"weights-improvement-19-1.9693.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W4cOeZjjDaw"
      },
      "source": [
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4SeGbMcnCPu"
      },
      "source": [
        "import sys"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llRayKoNjR62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27795a28-4ceb-4eff-a102-3f30a5814b30"
      },
      "source": [
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(\"Seed:\")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(1000):\n",
        "        x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "        x = x / float(n_vocab)\n",
        "        prediction = model.predict(x, verbose=0)\n",
        "        index = numpy.argmax(prediction)\n",
        "        result = int_to_char[index]\n",
        "        seq_in = [int_to_char[value] for value in pattern]\n",
        "        sys.stdout.write(result)\n",
        "        pattern.append(index)\n",
        "        pattern = pattern[1:len(pattern)]\n",
        "print(\"\\nDone.\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\"  your waist,'\n",
            "the duchess said after a pause: 'the reason is, that i'm doubtful about\n",
            "the temper of  \"\n",
            "the saalit in the dorse   \n",
            " '          nh thi sase theng would the waale  she marth wose the whilg  a dirmt whth the woine of the saalen in the same  and eere a little toaere to toine to thit mottle toine on the waale, and the whst hare to tae it the was andin. \n",
            "'whu,  said the mock turtle  'what a couldus youl mame to toyed to toe toing an inrer, and i so setl the cene tite then '\n",
            "\n",
            "'i maver the marter ' said the mock turtle. ''wolne io ' said the march hare.\n",
            "\n",
            "'well  the soiee of the soaer?' said the mock turtle. \n",
            "'wol kad tot toen that,' said the mock turtle. ''wolne io ' said the march hare.\n",
            "\n",
            "'well  the soiee of the soaer?' said the mock turtle. \n",
            "'wol kad tot toen that,' said the mock turtle. ''wolne io ' said the march hare.\n",
            "\n",
            "'well  the soiee of the soaer?' said the mock turtle. \n",
            "'wol kad tot toen that,' said the mock turtle. ''wolne io ' said the march hare.\n",
            "\n",
            "'well  the soiee of the soaer?' said the mock turtle. \n",
            "'wol kad tot toen that,' said the mock turtle. ''wolne io ' said the \n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7U4RYSPjR8p"
      },
      "source": [
        ""
      ],
      "execution_count": 36,
      "outputs": []
    }
  ]
}